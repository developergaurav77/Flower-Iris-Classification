{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ef9e03-51ec-4660-9456-82f94efcdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1f76b1-ff89-443e-a0d7-0039628f42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ca5c6b-31fa-4f84-a491-6c82ed86d548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ed7e95-4a08-42a8-8453-e77649bf690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "flower.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b3c2b1-329e-4d7d-8c73-919a4f93284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95c1be0d-1726-4cb5-94c4-b8d373a1f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flower.drop('species',axis=1)\n",
    "y = flower['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122c2f90-af49-41ce-9c71-319c90dd42dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96e99aa-33b0-4994-8c76-07fb30d0c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9beb5a-5e77-48b4-aae6-1cb123da34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb0eb4c5-1363-4b4a-a701-aca876b5a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71bc93fd-f253-4d4b-b10b-26967acdb10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ee3adc-220a-4a31-82d4-4e5a60488cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2fba7b-2ccc-41fc-abcc-a18a08bc2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f197027-1c31-4d52-86e5-887f754fdf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d26db961-f526-4c46-a2af-de448b040014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef31790-6d34-46df-bdb1-6f726443bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833db727-7bc8-4cd2-8960-9e919a311226",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3911e7d4-4477-4d29-bda1-930d76052766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7c11dfb-6ae9-4d34-a46b-2b342c17936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e1cd5a5-dd14-43fc-beeb-c8ea66eae374",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "965cebcd-16cc-4c7f-9f2b-b46ff4ab2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc62c3c6-8458-42ff-b3fa-72e7090edd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',verbose=1,patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0baa73cf-cc0c-4ab9-a9cc-7176217f8fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 4s 132ms/step - loss: 1.1208 - accuracy: 0.3143 - val_loss: 1.0776 - val_accuracy: 0.3778\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1136 - accuracy: 0.3143 - val_loss: 1.0720 - val_accuracy: 0.3778\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1059 - accuracy: 0.3143 - val_loss: 1.0668 - val_accuracy: 0.3778\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0993 - accuracy: 0.3143 - val_loss: 1.0616 - val_accuracy: 0.3778\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0927 - accuracy: 0.3143 - val_loss: 1.0566 - val_accuracy: 0.3778\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0860 - accuracy: 0.3143 - val_loss: 1.0518 - val_accuracy: 0.3778\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0797 - accuracy: 0.3143 - val_loss: 1.0468 - val_accuracy: 0.3778\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0733 - accuracy: 0.3143 - val_loss: 1.0418 - val_accuracy: 0.3778\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0667 - accuracy: 0.3143 - val_loss: 1.0369 - val_accuracy: 0.3778\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0602 - accuracy: 0.3143 - val_loss: 1.0319 - val_accuracy: 0.3778\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0537 - accuracy: 0.3238 - val_loss: 1.0272 - val_accuracy: 0.3778\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0480 - accuracy: 0.3238 - val_loss: 1.0226 - val_accuracy: 0.3778\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0418 - accuracy: 0.3333 - val_loss: 1.0180 - val_accuracy: 0.3778\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0361 - accuracy: 0.3429 - val_loss: 1.0134 - val_accuracy: 0.3778\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0303 - accuracy: 0.3524 - val_loss: 1.0089 - val_accuracy: 0.3778\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0248 - accuracy: 0.3619 - val_loss: 1.0044 - val_accuracy: 0.3778\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0188 - accuracy: 0.3619 - val_loss: 1.0000 - val_accuracy: 0.3778\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0131 - accuracy: 0.3619 - val_loss: 0.9956 - val_accuracy: 0.4000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0078 - accuracy: 0.3619 - val_loss: 0.9912 - val_accuracy: 0.4222\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0023 - accuracy: 0.3619 - val_loss: 0.9869 - val_accuracy: 0.4222\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9970 - accuracy: 0.3810 - val_loss: 0.9826 - val_accuracy: 0.4667\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9914 - accuracy: 0.4000 - val_loss: 0.9784 - val_accuracy: 0.4667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9861 - accuracy: 0.4190 - val_loss: 0.9741 - val_accuracy: 0.4889\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9807 - accuracy: 0.4381 - val_loss: 0.9699 - val_accuracy: 0.4889\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9754 - accuracy: 0.4476 - val_loss: 0.9656 - val_accuracy: 0.4889\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9702 - accuracy: 0.4381 - val_loss: 0.9612 - val_accuracy: 0.4889\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9646 - accuracy: 0.4381 - val_loss: 0.9568 - val_accuracy: 0.4889\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9590 - accuracy: 0.4286 - val_loss: 0.9524 - val_accuracy: 0.4667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9538 - accuracy: 0.4476 - val_loss: 0.9480 - val_accuracy: 0.4889\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9481 - accuracy: 0.4571 - val_loss: 0.9435 - val_accuracy: 0.4889\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9426 - accuracy: 0.5143 - val_loss: 0.9391 - val_accuracy: 0.4889\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9371 - accuracy: 0.5048 - val_loss: 0.9347 - val_accuracy: 0.4667\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9319 - accuracy: 0.5238 - val_loss: 0.9303 - val_accuracy: 0.4444\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9263 - accuracy: 0.5429 - val_loss: 0.9258 - val_accuracy: 0.4667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9210 - accuracy: 0.5524 - val_loss: 0.9212 - val_accuracy: 0.4889\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9155 - accuracy: 0.5619 - val_loss: 0.9166 - val_accuracy: 0.5556\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9100 - accuracy: 0.5714 - val_loss: 0.9120 - val_accuracy: 0.5556\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9047 - accuracy: 0.5905 - val_loss: 0.9074 - val_accuracy: 0.5556\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8993 - accuracy: 0.6095 - val_loss: 0.9029 - val_accuracy: 0.5778\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8936 - accuracy: 0.6190 - val_loss: 0.8982 - val_accuracy: 0.5778\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8882 - accuracy: 0.6476 - val_loss: 0.8936 - val_accuracy: 0.5556\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8824 - accuracy: 0.6762 - val_loss: 0.8890 - val_accuracy: 0.5556\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8769 - accuracy: 0.6667 - val_loss: 0.8843 - val_accuracy: 0.5556\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8713 - accuracy: 0.6476 - val_loss: 0.8797 - val_accuracy: 0.5333\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8660 - accuracy: 0.6571 - val_loss: 0.8750 - val_accuracy: 0.5556\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8601 - accuracy: 0.6571 - val_loss: 0.8703 - val_accuracy: 0.5556\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8545 - accuracy: 0.6667 - val_loss: 0.8657 - val_accuracy: 0.5778\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8493 - accuracy: 0.6857 - val_loss: 0.8610 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8439 - accuracy: 0.6857 - val_loss: 0.8564 - val_accuracy: 0.6222\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8384 - accuracy: 0.6762 - val_loss: 0.8518 - val_accuracy: 0.6222\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8332 - accuracy: 0.6952 - val_loss: 0.8474 - val_accuracy: 0.6222\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8278 - accuracy: 0.6952 - val_loss: 0.8430 - val_accuracy: 0.6444\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8229 - accuracy: 0.7048 - val_loss: 0.8388 - val_accuracy: 0.6444\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8179 - accuracy: 0.7143 - val_loss: 0.8346 - val_accuracy: 0.6444\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8130 - accuracy: 0.7143 - val_loss: 0.8304 - val_accuracy: 0.6444\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8082 - accuracy: 0.7048 - val_loss: 0.8264 - val_accuracy: 0.6444\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8034 - accuracy: 0.7048 - val_loss: 0.8224 - val_accuracy: 0.6444\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7990 - accuracy: 0.6857 - val_loss: 0.8186 - val_accuracy: 0.6222\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7939 - accuracy: 0.6857 - val_loss: 0.8147 - val_accuracy: 0.6222\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7893 - accuracy: 0.6857 - val_loss: 0.8108 - val_accuracy: 0.6222\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7846 - accuracy: 0.6857 - val_loss: 0.8070 - val_accuracy: 0.6222\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7803 - accuracy: 0.6857 - val_loss: 0.8033 - val_accuracy: 0.6222\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7757 - accuracy: 0.6952 - val_loss: 0.7995 - val_accuracy: 0.6222\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7715 - accuracy: 0.6952 - val_loss: 0.7958 - val_accuracy: 0.6222\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7670 - accuracy: 0.6952 - val_loss: 0.7920 - val_accuracy: 0.6222\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7626 - accuracy: 0.6952 - val_loss: 0.7883 - val_accuracy: 0.6222\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7585 - accuracy: 0.6952 - val_loss: 0.7846 - val_accuracy: 0.6222\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7539 - accuracy: 0.6952 - val_loss: 0.7809 - val_accuracy: 0.6222\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7499 - accuracy: 0.7048 - val_loss: 0.7772 - val_accuracy: 0.6222\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7454 - accuracy: 0.7048 - val_loss: 0.7735 - val_accuracy: 0.6222\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7414 - accuracy: 0.7048 - val_loss: 0.7698 - val_accuracy: 0.6222\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7372 - accuracy: 0.7048 - val_loss: 0.7661 - val_accuracy: 0.6222\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7330 - accuracy: 0.7048 - val_loss: 0.7625 - val_accuracy: 0.6222\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7290 - accuracy: 0.7048 - val_loss: 0.7589 - val_accuracy: 0.6222\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7248 - accuracy: 0.7048 - val_loss: 0.7554 - val_accuracy: 0.6222\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7208 - accuracy: 0.7048 - val_loss: 0.7520 - val_accuracy: 0.6222\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7168 - accuracy: 0.7048 - val_loss: 0.7486 - val_accuracy: 0.6222\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7129 - accuracy: 0.6952 - val_loss: 0.7454 - val_accuracy: 0.6222\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7092 - accuracy: 0.6857 - val_loss: 0.7422 - val_accuracy: 0.6222\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7052 - accuracy: 0.6857 - val_loss: 0.7387 - val_accuracy: 0.6222\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7017 - accuracy: 0.6952 - val_loss: 0.7354 - val_accuracy: 0.6222\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6978 - accuracy: 0.6952 - val_loss: 0.7319 - val_accuracy: 0.6222\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6943 - accuracy: 0.7048 - val_loss: 0.7285 - val_accuracy: 0.6222\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6909 - accuracy: 0.7048 - val_loss: 0.7251 - val_accuracy: 0.6222\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6872 - accuracy: 0.7048 - val_loss: 0.7219 - val_accuracy: 0.6222\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6836 - accuracy: 0.7048 - val_loss: 0.7187 - val_accuracy: 0.6222\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6803 - accuracy: 0.7048 - val_loss: 0.7156 - val_accuracy: 0.6222\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6766 - accuracy: 0.7048 - val_loss: 0.7126 - val_accuracy: 0.6222\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6732 - accuracy: 0.7048 - val_loss: 0.7096 - val_accuracy: 0.6222\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6698 - accuracy: 0.7048 - val_loss: 0.7065 - val_accuracy: 0.6222\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6665 - accuracy: 0.7048 - val_loss: 0.7036 - val_accuracy: 0.6222\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6631 - accuracy: 0.7048 - val_loss: 0.7006 - val_accuracy: 0.6222\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6598 - accuracy: 0.7048 - val_loss: 0.6976 - val_accuracy: 0.6222\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6566 - accuracy: 0.7048 - val_loss: 0.6948 - val_accuracy: 0.6222\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6533 - accuracy: 0.7048 - val_loss: 0.6919 - val_accuracy: 0.6222\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6502 - accuracy: 0.7048 - val_loss: 0.6891 - val_accuracy: 0.6444\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6469 - accuracy: 0.7048 - val_loss: 0.6862 - val_accuracy: 0.6444\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6438 - accuracy: 0.7048 - val_loss: 0.6834 - val_accuracy: 0.6444\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6407 - accuracy: 0.7048 - val_loss: 0.6807 - val_accuracy: 0.6444\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6377 - accuracy: 0.7048 - val_loss: 0.6781 - val_accuracy: 0.6444\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6345 - accuracy: 0.7048 - val_loss: 0.6755 - val_accuracy: 0.6444\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6317 - accuracy: 0.7048 - val_loss: 0.6730 - val_accuracy: 0.6222\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6286 - accuracy: 0.7048 - val_loss: 0.6704 - val_accuracy: 0.6222\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6257 - accuracy: 0.7048 - val_loss: 0.6679 - val_accuracy: 0.6222\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6228 - accuracy: 0.7048 - val_loss: 0.6652 - val_accuracy: 0.6444\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6202 - accuracy: 0.7048 - val_loss: 0.6625 - val_accuracy: 0.6444\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6171 - accuracy: 0.7048 - val_loss: 0.6600 - val_accuracy: 0.6444\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6144 - accuracy: 0.7048 - val_loss: 0.6576 - val_accuracy: 0.6444\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6117 - accuracy: 0.7048 - val_loss: 0.6551 - val_accuracy: 0.6444\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6090 - accuracy: 0.7048 - val_loss: 0.6527 - val_accuracy: 0.6444\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.7048 - val_loss: 0.6505 - val_accuracy: 0.6444\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6037 - accuracy: 0.7048 - val_loss: 0.6481 - val_accuracy: 0.6444\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6012 - accuracy: 0.7048 - val_loss: 0.6459 - val_accuracy: 0.6444\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5986 - accuracy: 0.7048 - val_loss: 0.6436 - val_accuracy: 0.6444\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5959 - accuracy: 0.7048 - val_loss: 0.6414 - val_accuracy: 0.6444\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5934 - accuracy: 0.7048 - val_loss: 0.6393 - val_accuracy: 0.6444\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5909 - accuracy: 0.7048 - val_loss: 0.6372 - val_accuracy: 0.6222\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5884 - accuracy: 0.7048 - val_loss: 0.6350 - val_accuracy: 0.6222\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5859 - accuracy: 0.7048 - val_loss: 0.6328 - val_accuracy: 0.6444\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5834 - accuracy: 0.7048 - val_loss: 0.6308 - val_accuracy: 0.6222\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5809 - accuracy: 0.7048 - val_loss: 0.6287 - val_accuracy: 0.6444\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5786 - accuracy: 0.7048 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5762 - accuracy: 0.7048 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5740 - accuracy: 0.7048 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5717 - accuracy: 0.7048 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5694 - accuracy: 0.7048 - val_loss: 0.6171 - val_accuracy: 0.6667\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5673 - accuracy: 0.7048 - val_loss: 0.6149 - val_accuracy: 0.6667\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5651 - accuracy: 0.7048 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5629 - accuracy: 0.7048 - val_loss: 0.6106 - val_accuracy: 0.6667\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5607 - accuracy: 0.7048 - val_loss: 0.6087 - val_accuracy: 0.6667\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5587 - accuracy: 0.7048 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5567 - accuracy: 0.7143 - val_loss: 0.6045 - val_accuracy: 0.6667\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5545 - accuracy: 0.7238 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5524 - accuracy: 0.7238 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5505 - accuracy: 0.7238 - val_loss: 0.5987 - val_accuracy: 0.6667\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5485 - accuracy: 0.7238 - val_loss: 0.5968 - val_accuracy: 0.6667\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5465 - accuracy: 0.7238 - val_loss: 0.5952 - val_accuracy: 0.6667\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5446 - accuracy: 0.7238 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5428 - accuracy: 0.7238 - val_loss: 0.5917 - val_accuracy: 0.6667\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5408 - accuracy: 0.7238 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5389 - accuracy: 0.7238 - val_loss: 0.5881 - val_accuracy: 0.6889\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5371 - accuracy: 0.7238 - val_loss: 0.5863 - val_accuracy: 0.6889\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5352 - accuracy: 0.7238 - val_loss: 0.5846 - val_accuracy: 0.6889\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5334 - accuracy: 0.7238 - val_loss: 0.5831 - val_accuracy: 0.6889\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5315 - accuracy: 0.7238 - val_loss: 0.5814 - val_accuracy: 0.6889\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5298 - accuracy: 0.7238 - val_loss: 0.5798 - val_accuracy: 0.6889\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5280 - accuracy: 0.7238 - val_loss: 0.5784 - val_accuracy: 0.6889\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5262 - accuracy: 0.7238 - val_loss: 0.5768 - val_accuracy: 0.6889\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5245 - accuracy: 0.7238 - val_loss: 0.5751 - val_accuracy: 0.6889\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5228 - accuracy: 0.7238 - val_loss: 0.5735 - val_accuracy: 0.6889\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5211 - accuracy: 0.7238 - val_loss: 0.5719 - val_accuracy: 0.6889\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5196 - accuracy: 0.7333 - val_loss: 0.5700 - val_accuracy: 0.6889\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5178 - accuracy: 0.7333 - val_loss: 0.5683 - val_accuracy: 0.6889\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5163 - accuracy: 0.7333 - val_loss: 0.5667 - val_accuracy: 0.6889\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5147 - accuracy: 0.7333 - val_loss: 0.5650 - val_accuracy: 0.6889\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5133 - accuracy: 0.7429 - val_loss: 0.5633 - val_accuracy: 0.6889\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5118 - accuracy: 0.7524 - val_loss: 0.5617 - val_accuracy: 0.6889\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5102 - accuracy: 0.7524 - val_loss: 0.5602 - val_accuracy: 0.6889\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5088 - accuracy: 0.7619 - val_loss: 0.5586 - val_accuracy: 0.6889\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5073 - accuracy: 0.7714 - val_loss: 0.5571 - val_accuracy: 0.6889\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5058 - accuracy: 0.7714 - val_loss: 0.5558 - val_accuracy: 0.6889\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.7714 - val_loss: 0.5545 - val_accuracy: 0.6889\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5028 - accuracy: 0.7714 - val_loss: 0.5532 - val_accuracy: 0.6889\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5014 - accuracy: 0.7714 - val_loss: 0.5520 - val_accuracy: 0.6889\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4999 - accuracy: 0.7714 - val_loss: 0.5508 - val_accuracy: 0.6889\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4986 - accuracy: 0.7714 - val_loss: 0.5496 - val_accuracy: 0.6889\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4971 - accuracy: 0.7524 - val_loss: 0.5483 - val_accuracy: 0.6889\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4957 - accuracy: 0.7524 - val_loss: 0.5470 - val_accuracy: 0.6889\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4945 - accuracy: 0.7524 - val_loss: 0.5458 - val_accuracy: 0.6889\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4931 - accuracy: 0.7619 - val_loss: 0.5443 - val_accuracy: 0.6889\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4917 - accuracy: 0.7714 - val_loss: 0.5429 - val_accuracy: 0.6889\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4904 - accuracy: 0.7714 - val_loss: 0.5417 - val_accuracy: 0.6889\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4890 - accuracy: 0.7714 - val_loss: 0.5405 - val_accuracy: 0.6889\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4877 - accuracy: 0.7714 - val_loss: 0.5391 - val_accuracy: 0.6889\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.7714 - val_loss: 0.5377 - val_accuracy: 0.6889\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4852 - accuracy: 0.7714 - val_loss: 0.5365 - val_accuracy: 0.6889\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4839 - accuracy: 0.7810 - val_loss: 0.5355 - val_accuracy: 0.6889\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4827 - accuracy: 0.7714 - val_loss: 0.5346 - val_accuracy: 0.6889\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4815 - accuracy: 0.7714 - val_loss: 0.5337 - val_accuracy: 0.6889\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4802 - accuracy: 0.7714 - val_loss: 0.5328 - val_accuracy: 0.6889\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4793 - accuracy: 0.7714 - val_loss: 0.5319 - val_accuracy: 0.6889\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4779 - accuracy: 0.7714 - val_loss: 0.5307 - val_accuracy: 0.6889\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4767 - accuracy: 0.7714 - val_loss: 0.5294 - val_accuracy: 0.6889\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4756 - accuracy: 0.7714 - val_loss: 0.5282 - val_accuracy: 0.6889\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4743 - accuracy: 0.7714 - val_loss: 0.5268 - val_accuracy: 0.6889\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4731 - accuracy: 0.7810 - val_loss: 0.5254 - val_accuracy: 0.6889\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4721 - accuracy: 0.8000 - val_loss: 0.5240 - val_accuracy: 0.6889\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4709 - accuracy: 0.8095 - val_loss: 0.5228 - val_accuracy: 0.6889\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4698 - accuracy: 0.8095 - val_loss: 0.5216 - val_accuracy: 0.7111\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4686 - accuracy: 0.8095 - val_loss: 0.5205 - val_accuracy: 0.7111\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4675 - accuracy: 0.8190 - val_loss: 0.5191 - val_accuracy: 0.7556\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4664 - accuracy: 0.8286 - val_loss: 0.5178 - val_accuracy: 0.7556\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4655 - accuracy: 0.8286 - val_loss: 0.5166 - val_accuracy: 0.7556\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4644 - accuracy: 0.8286 - val_loss: 0.5155 - val_accuracy: 0.7556\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4633 - accuracy: 0.8286 - val_loss: 0.5145 - val_accuracy: 0.7556\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4622 - accuracy: 0.8286 - val_loss: 0.5136 - val_accuracy: 0.7556\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4612 - accuracy: 0.8286 - val_loss: 0.5127 - val_accuracy: 0.7556\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4603 - accuracy: 0.8286 - val_loss: 0.5118 - val_accuracy: 0.7556\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4590 - accuracy: 0.8286 - val_loss: 0.5110 - val_accuracy: 0.7556\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4581 - accuracy: 0.8286 - val_loss: 0.5103 - val_accuracy: 0.7556\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4572 - accuracy: 0.8286 - val_loss: 0.5097 - val_accuracy: 0.7556\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4560 - accuracy: 0.8286 - val_loss: 0.5089 - val_accuracy: 0.7556\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4551 - accuracy: 0.8286 - val_loss: 0.5082 - val_accuracy: 0.7333\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4542 - accuracy: 0.8286 - val_loss: 0.5073 - val_accuracy: 0.7333\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4532 - accuracy: 0.8286 - val_loss: 0.5062 - val_accuracy: 0.7556\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4522 - accuracy: 0.8286 - val_loss: 0.5053 - val_accuracy: 0.7556\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4512 - accuracy: 0.8286 - val_loss: 0.5042 - val_accuracy: 0.7556\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4502 - accuracy: 0.8286 - val_loss: 0.5032 - val_accuracy: 0.7556\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4492 - accuracy: 0.8286 - val_loss: 0.5020 - val_accuracy: 0.7556\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4483 - accuracy: 0.8286 - val_loss: 0.5010 - val_accuracy: 0.7556\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4475 - accuracy: 0.8286 - val_loss: 0.5002 - val_accuracy: 0.7556\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4465 - accuracy: 0.8286 - val_loss: 0.4992 - val_accuracy: 0.7556\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4455 - accuracy: 0.8381 - val_loss: 0.4984 - val_accuracy: 0.7556\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4446 - accuracy: 0.8381 - val_loss: 0.4975 - val_accuracy: 0.7556\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4437 - accuracy: 0.8381 - val_loss: 0.4966 - val_accuracy: 0.7778\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4428 - accuracy: 0.8381 - val_loss: 0.4957 - val_accuracy: 0.7778\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4420 - accuracy: 0.8381 - val_loss: 0.4947 - val_accuracy: 0.7778\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4411 - accuracy: 0.8381 - val_loss: 0.4936 - val_accuracy: 0.7778\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4402 - accuracy: 0.8381 - val_loss: 0.4926 - val_accuracy: 0.7778\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4393 - accuracy: 0.8381 - val_loss: 0.4916 - val_accuracy: 0.7778\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4385 - accuracy: 0.8381 - val_loss: 0.4905 - val_accuracy: 0.7778\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4378 - accuracy: 0.8381 - val_loss: 0.4894 - val_accuracy: 0.7778\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4369 - accuracy: 0.8381 - val_loss: 0.4884 - val_accuracy: 0.7778\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4361 - accuracy: 0.8381 - val_loss: 0.4875 - val_accuracy: 0.7778\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4352 - accuracy: 0.8381 - val_loss: 0.4867 - val_accuracy: 0.7778\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4343 - accuracy: 0.8381 - val_loss: 0.4861 - val_accuracy: 0.7778\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4334 - accuracy: 0.8381 - val_loss: 0.4855 - val_accuracy: 0.7778\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4326 - accuracy: 0.8381 - val_loss: 0.4852 - val_accuracy: 0.7778\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4318 - accuracy: 0.8381 - val_loss: 0.4848 - val_accuracy: 0.7778\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4311 - accuracy: 0.8381 - val_loss: 0.4843 - val_accuracy: 0.7778\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4306 - accuracy: 0.8381 - val_loss: 0.4837 - val_accuracy: 0.7778\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4297 - accuracy: 0.8381 - val_loss: 0.4828 - val_accuracy: 0.7778\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4288 - accuracy: 0.8381 - val_loss: 0.4817 - val_accuracy: 0.7778\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.8381 - val_loss: 0.4808 - val_accuracy: 0.7778\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4272 - accuracy: 0.8381 - val_loss: 0.4798 - val_accuracy: 0.7778\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4266 - accuracy: 0.8381 - val_loss: 0.4786 - val_accuracy: 0.7778\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4255 - accuracy: 0.8381 - val_loss: 0.4778 - val_accuracy: 0.7778\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4248 - accuracy: 0.8381 - val_loss: 0.4769 - val_accuracy: 0.7778\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4240 - accuracy: 0.8381 - val_loss: 0.4761 - val_accuracy: 0.7778\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.8381 - val_loss: 0.4752 - val_accuracy: 0.7778\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.8381 - val_loss: 0.4743 - val_accuracy: 0.7778\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4217 - accuracy: 0.8381 - val_loss: 0.4735 - val_accuracy: 0.7778\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4209 - accuracy: 0.8381 - val_loss: 0.4727 - val_accuracy: 0.7778\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4202 - accuracy: 0.8476 - val_loss: 0.4717 - val_accuracy: 0.7778\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4198 - accuracy: 0.8476 - val_loss: 0.4706 - val_accuracy: 0.7778\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.8476 - val_loss: 0.4698 - val_accuracy: 0.7778\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4180 - accuracy: 0.8476 - val_loss: 0.4691 - val_accuracy: 0.7778\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4173 - accuracy: 0.8476 - val_loss: 0.4685 - val_accuracy: 0.7778\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4165 - accuracy: 0.8476 - val_loss: 0.4678 - val_accuracy: 0.7778\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4158 - accuracy: 0.8476 - val_loss: 0.4671 - val_accuracy: 0.7778\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4150 - accuracy: 0.8476 - val_loss: 0.4665 - val_accuracy: 0.7778\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8476 - val_loss: 0.4660 - val_accuracy: 0.7778\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4136 - accuracy: 0.8476 - val_loss: 0.4654 - val_accuracy: 0.7778\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.8476 - val_loss: 0.4648 - val_accuracy: 0.7778\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4122 - accuracy: 0.8476 - val_loss: 0.4643 - val_accuracy: 0.7778\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.8476 - val_loss: 0.4637 - val_accuracy: 0.7778\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4109 - accuracy: 0.8476 - val_loss: 0.4631 - val_accuracy: 0.7778\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4102 - accuracy: 0.8476 - val_loss: 0.4625 - val_accuracy: 0.7778\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4095 - accuracy: 0.8476 - val_loss: 0.4618 - val_accuracy: 0.7778\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4089 - accuracy: 0.8476 - val_loss: 0.4610 - val_accuracy: 0.7778\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4082 - accuracy: 0.8476 - val_loss: 0.4600 - val_accuracy: 0.7778\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4076 - accuracy: 0.8476 - val_loss: 0.4592 - val_accuracy: 0.7778\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.8476 - val_loss: 0.4587 - val_accuracy: 0.7778\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4059 - accuracy: 0.8476 - val_loss: 0.4585 - val_accuracy: 0.7778\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4057 - accuracy: 0.8476 - val_loss: 0.4585 - val_accuracy: 0.7778\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4051 - accuracy: 0.8476 - val_loss: 0.4580 - val_accuracy: 0.7778\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.8476 - val_loss: 0.4573 - val_accuracy: 0.7778\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4038 - accuracy: 0.8476 - val_loss: 0.4568 - val_accuracy: 0.7778\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4032 - accuracy: 0.8476 - val_loss: 0.4561 - val_accuracy: 0.7778\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4025 - accuracy: 0.8476 - val_loss: 0.4550 - val_accuracy: 0.7778\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4017 - accuracy: 0.8476 - val_loss: 0.4541 - val_accuracy: 0.7778\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4011 - accuracy: 0.8476 - val_loss: 0.4531 - val_accuracy: 0.7778\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4004 - accuracy: 0.8476 - val_loss: 0.4522 - val_accuracy: 0.7778\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3997 - accuracy: 0.8476 - val_loss: 0.4515 - val_accuracy: 0.7778\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8476 - val_loss: 0.4506 - val_accuracy: 0.7778\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3984 - accuracy: 0.8476 - val_loss: 0.4498 - val_accuracy: 0.7778\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3977 - accuracy: 0.8476 - val_loss: 0.4491 - val_accuracy: 0.7778\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.8476 - val_loss: 0.4486 - val_accuracy: 0.7778\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3965 - accuracy: 0.8476 - val_loss: 0.4482 - val_accuracy: 0.7778\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3959 - accuracy: 0.8476 - val_loss: 0.4477 - val_accuracy: 0.7778\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.8476 - val_loss: 0.4473 - val_accuracy: 0.7778\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3949 - accuracy: 0.8476 - val_loss: 0.4469 - val_accuracy: 0.7778\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3942 - accuracy: 0.8476 - val_loss: 0.4464 - val_accuracy: 0.7778\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3936 - accuracy: 0.8476 - val_loss: 0.4459 - val_accuracy: 0.7778\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3930 - accuracy: 0.8476 - val_loss: 0.4453 - val_accuracy: 0.7778\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.8476 - val_loss: 0.4445 - val_accuracy: 0.7778\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3918 - accuracy: 0.8476 - val_loss: 0.4434 - val_accuracy: 0.7778\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3909 - accuracy: 0.8476 - val_loss: 0.4424 - val_accuracy: 0.7778\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3901 - accuracy: 0.8571 - val_loss: 0.4413 - val_accuracy: 0.7778\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3895 - accuracy: 0.8571 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3890 - accuracy: 0.8571 - val_loss: 0.4391 - val_accuracy: 0.8000\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3886 - accuracy: 0.8571 - val_loss: 0.4383 - val_accuracy: 0.8000\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3878 - accuracy: 0.8571 - val_loss: 0.4377 - val_accuracy: 0.8000\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3873 - accuracy: 0.8571 - val_loss: 0.4371 - val_accuracy: 0.8000\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3866 - accuracy: 0.8571 - val_loss: 0.4362 - val_accuracy: 0.8000\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3859 - accuracy: 0.8571 - val_loss: 0.4355 - val_accuracy: 0.8000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3853 - accuracy: 0.8571 - val_loss: 0.4347 - val_accuracy: 0.8222\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3847 - accuracy: 0.8571 - val_loss: 0.4339 - val_accuracy: 0.8222\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3842 - accuracy: 0.8571 - val_loss: 0.4332 - val_accuracy: 0.8222\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3836 - accuracy: 0.8571 - val_loss: 0.4327 - val_accuracy: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18f442d2df0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,\n",
    "          y=y_train,\n",
    "          epochs=300,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(scaled_X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eea4675f-3d74-4b0f-b709-b8a76600e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba9dbd5d-547c-4366-b1ea-627f90ea6af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.120833</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.077636</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.113589</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.072010</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.105928</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.066793</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.099253</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.061580</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.092734</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>1.056631</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.120833  0.314286  1.077636      0.377778\n",
       "1  1.113589  0.314286  1.072010      0.377778\n",
       "2  1.105928  0.314286  1.066793      0.377778\n",
       "3  1.099253  0.314286  1.061580      0.377778\n",
       "4  1.092734  0.314286  1.056631      0.377778"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_loss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f8f031-9cc1-4297-ae6b-d683da4c5a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flower_loss[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57eb5624-2b79-4a93-ad47-050e316d3b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuAklEQVR4nO3deXxU9b3/8dcnySQh+84WIAHZN5FNcWNxwZVqsWKtVW7Vciv2qrdVaxfpre3Pa9XWViuX9qrVqlyvll5rrRYMiFqpQAVlSRBJSAKYycJkg6zz/f1xJgthJpkkM5kln+fjkcfMnDlz5nPmwDsn3/me71eMMSillAp9EYEuQCmllG9ooCulVJjQQFdKqTChga6UUmFCA10ppcJEVKDeOCMjw+Tk5ATq7ZVSKiTt3LmzwhiT6e65gAV6Tk4OO3bsCNTbK6VUSBKRw56e0yYXpZQKExroSikVJjTQlVIqTASsDd2d5uZmSktLaWhoCHQpCoiNjSU7OxubzRboUpRSXgiqQC8tLSUxMZGcnBxEJNDlDGrGGCorKyktLSU3NzfQ5SilvBBUTS4NDQ2kp6drmAcBESE9PV3/WlIqhARVoAMa5kFEj4VSoSWomlyUUirUtDoNz35QSM3JZq9fMycnjQsmuL02qF800JVSqh/eP1jBQ3/ZD4C3f9SuunCcBno4aWlpISpKP36lQt3mfDuxtgh2/egSYm2RAa0l6NrQg8GXvvQlZs+ezdSpU1m3bh0Ab731FmeddRYzZ85kyZIlANTV1bFy5UqmT5/OjBkzeO211wBISEho39arr77KLbfcAsAtt9zCPffcw6JFi7jvvvv46KOPWLBgAbNmzWLBggUUFBQA0Nrayne+85327f7617/mnXfe4Zprrmnf7saNG7n22msH4uNQasC0Og0nm1pD6icv386CcRkBD3MI4jP0H/95L/uO1vh0m1NGJPHgVVN7XO+ZZ54hLS2NkydPMnfuXJYtW8Ztt93G1q1byc3NpaqqCoCf/OQnJCcn8+mnnwJw/PjxHrd94MABNm3aRGRkJDU1NWzdupWoqCg2bdrEAw88wGuvvca6desoLCzk448/JioqiqqqKlJTU7njjjsoLy8nMzOTZ599lpUrV/bvA1EqiLS0Oln02BZKqk4GupReu+2CsYEuAQjiQA+kX/3qV2zYsAGAkpIS1q1bxwUXXNDeHzstLQ2ATZs2sX79+vbXpaam9rjt6667jshI6zd5dXU1N998M5999hkiQnNzc/t2V61a1d4k0/Z+N910E3/4wx9YuXIlH374Ic8//7yP9lipwPtnsYOSqpPcMG8UY9LjA12O12KiIlh+VnagywCCONC9OZP2hy1btrBp0yY+/PBD4uLiWLhwITNnzmxvDunMGOO2a1/nZV37ccfHd/xD/eEPf8iiRYvYsGEDRUVFLFy4sNvtrly5kquuuorY2Fiuu+46bYNXYSUv305UhPC9yyeTFKtXJ/eFJkIX1dXVpKamEhcXR35+Ptu2baOxsZF3332XwsLC9iaXtLQ0LrnkEp588kl++ctfAlaTS2pqKkOHDmX//v1MnDiRDRs2kJiY6PG9Ro4cCcBzzz3XvvySSy5h7dq1LFy4sL3JJS0tjREjRjBixAgeeughNm7c6O+PQg1CB8pqefmjYowZ+Pd+a88XzM1J0zDvBw30LpYuXcratWuZMWMGEydO5OyzzyYzM5N169Zx7bXX4nQ6ycrKYuPGjfzgBz/gjjvuYNq0aURGRvLggw9y7bXX8vDDD3PllVcyatQopk2bRl1dndv3uvfee7n55pt5/PHHWbx4cfvyW2+9lQMHDjBjxgxsNhu33XYbq1evBuDGG2+kvLycKVOmDMjnoQaXJ975jLf2fEFCzMBHQ4TAinmjBvx9w4mYQPwqBubMmWO6TnCxf/9+Jk+eHJB6QsXq1auZNWsW3/jGNwbk/fSYDB7NrU7O+slGLps2jEeWzwx0OcoDEdlpjJnj7jk9Qw8hs2fPJj4+nsceeyzQpagg0NDcSnUvrk7sye4SB7UNLSyelOWzbaqBpYEeQnbu3BnoElSQMMZw2RPvUVhR79PtRkdGcN5431/BqAaGBrpSIWjv0RoKK+q5cf5opo5I9tl2czPiA9J+rnxDj5xSIWhzvh2Auy6aQGZiTICrUd0yBl77BlQVdiybeQPMv93nb6WX/isVgvIK7MzMTtYwDwV1ZbDnNWhphLh06yc6zi9vpWfoSoWYyrpGdpU4+Lcl4wNdivKGo9i6vWgNTLjEr2+lZ+hKhZgtBeUYA0smDQ10Kcobxw9btymj/f5WeobeDwkJCR4vGlLK1yrrGqmsb+Kve46RmRjD1BFJgS5JecPRFuj+v2hKAz0M6Njq4a+huZXFj73b3u98xdxRREToFIEhwVEM8ZkQ7f8Bx7xKARFZCjwBRAK/M8Y83OX5ZOAPwGjXNh81xjzbr8r+ej988Wm/NnGaYdPhsoc9Pn3fffcxZswYvvWtbwGwZs0aRIStW7dy/Phxmpubeeihh1i2bFmPb1VXV8eyZcvcvu7555/n0UcfRUSYMWMGL7zwAmVlZaxatYpDhw4B8PTTTzNixAiuvPJK9uzZA8Cjjz5KXV0da9asYeHChSxYsIAPPviAq6++mgkTJvDQQw/R1NREeno6L774IkOHDqWuro4777yTHTt2ICI8+OCDOBwO9uzZwy9+8QsAfvvb37J//34ef/zxfn28yn+2Haqk+mQzd180gfFDE1gwLj3QJSlvOQ4PSHMLeBHoIhIJPAVcDJQC20XkdWPMvk6r3QHsM8ZcJSKZQIGIvGiMafJL1X6yYsUK7rrrrvZAf+WVV3jrrbe4++67SUpKoqKigrPPPpurr766xwmUY2Nj2bBhw2mv27dvHz/96U/54IMPyMjIaB9b/dvf/jYXXnghGzZsoLW1lbq6uh7HV3c4HLz77ruANTDYtm3bEBF+97vf8cgjj/DYY4+5HbM9OjqaGTNm8Mgjj2Cz2Xj22Wf5r//6r/5+fMqP2mbF+eaFY4NiIgXVC45iGD4wQyl4c4Y+DzhojDkEICLrgWVA50A3QKJYKZcAVAEt/aqsmzNpf5k1axZ2u52jR49SXl5Oamoqw4cP5+6772br1q1ERERw5MgRysrKGDZsWLfbMsbwwAMPnPa6vLw8li9fTkZGBtAx1nleXl77+OaRkZEkJyf3GOjXX399+/3S0lKuv/56jh07RlNTU/vY7Z7GbF+8eDFvvPEGkydPprm5menTp/fy01IDKa/AznlnBMesOMqNlkb4811wsur0544fhslXD0gZ3gT6SKCk0+NSYH6XdZ4EXgeOAonA9cYYZ9cNicjtwO0Ao0cPzJ8gvbV8+XJeffVVvvjiC1asWMGLL75IeXk5O3fuxGazkZOTc9oY5+54ep2nsc7diYqKwuns+Bi7G1v9zjvv5J577uHqq69my5YtrFmzBvA8tvqtt97Kz372MyZNmqQzHwW54/VNlFSd5Otn5wS6FOXJF3tg90uQNg5iEk59bsSZMPGyASnDm26L7tKn6xCNlwK7gBHAmcCTInLaV/DGmHXGmDnGmDmZmcE5XsSKFStYv349r776KsuXL6e6upqsrCxsNhubN2/m8OHDXm3H0+uWLFnCK6+8QmVlJUB7k8uSJUt4+umnAWtO0ZqaGoYOHYrdbqeyspLGxkbeeOONbt+vbWz13//+9+3L28Zsb9N21j9//nxKSkp46aWXuOGGG7z9eFQAFFZa47WMzQydWXwGnbaeLNe/AN/ceurPbXkw+uwBKcObQC8FOve3ycY6E+9sJfBHYzkIFAKTfFPiwJo6dSq1tbWMHDmS4cOHc+ONN7Jjxw7mzJnDiy++yKRJ3u2Wp9dNnTqV73//+1x44YXMnDmTe+65B4AnnniCzZs3M336dGbPns3evXux2Wz86Ec/Yv78+Vx55ZXdvveaNWu47rrrOP/889ubcwB+8IMfcPz4caZNm8bMmTPZvHlz+3Nf+cpXOPfcc72aOk8FTmG5Feg5GRroQast0JMDPJ67MabbH6xmmUNALhAN7AamdlnnaWCN6/5Q4AiQ0d12Z8+ebbrat2/facuU/1xxxRVm06ZN3a6jxyTwHn073+Te/4ZpbG4NdCnKkz/fZczDYwbkrYAdxkOu9niGboxpAVYDbwP7gVeMMXtFZJWIrHKt9hNggYh8CrwD3GeMqfDZbx3lUw6HgwkTJjBkyBCWLFkS6HJUDw5V1DMqLY7oKL2wO2g5iiFlTKCr8K4fujHmTeDNLsvWdrp/FPDvIAVB6tNPP+Wmm246ZVlMTAz/+Mc/AlRRz1JSUjhw4ECgy1BeKqqoJyddm1uCmqMYMgPfyhx0lxeaXvQCCQbTp09n165dgS7DL0yApiccLGobmvn+hj1899KJjEpzP/qeMYaiinrm5qQNcHXKa8ZYgT4+8Oe0QRXosbGxVFZWkp6eHlKhHo6MMVRWVhIbGxvoUsLWpv1lvL77KDnpcdxzyUS36+w9WkN9UyvTR/puEguvlBfAtqfBtA7s+4ai1mZoaYDUnEBXElyBnp2dTWlpKeXl5YEuRWH9gs3Ozg50GWErL9/6d55XYPcY6O/styMCCycOcDfffz4PO5+DxO4voFMuqTkw+pxAVxFcgW6z2dqvcFQqmJ1samVbYaXbZqnUuGhmje7oCup0GrYdqqShpeNs1xh4t8BOTFQEe47U8MYnR4mLPv0q0L/uOcbM7BTSEwZ4IgtHMWSMh9XbB/Z9Vb8EVaArFSqe2nyQJzcf9Pj8e/cuam8X/9u+Mlb9wf0E3/ctncQjb+ez+qWPPW7rvqUB+LLNUTxgA0op39FAV6oPNu0vY9boFNZcNfWU5QVltdz76icctNe1B/qm/WUkD7Hx+3+Zd8pl1zG2CCYOTWTptGHUuIbF7SoyQpg0LNFfu+GZoxhGnjXw76v6RQNdqV464jhJ/he1PHD5JGaOSjnluezUIQAUVtSzCKu5ZUuBnQsnZHJml3Xb5AbbFaCNtdYgU3qGHnL0SgWleikv3w7AYjdTwKXFR5MYG0VhhXW5/idHqqmoa2LxpKwBrbFf2ubA1EAPORroSvXS5nw7o9PiGOdmsCwRYWxGPEWuAbXy8u1ECFw4ITgHo3OrPdBzAlqG6j1tclGqFxqaW/n75xWsmDva47USORnx7CiyRrXcnG9n1uhUUuOjfVvI3j/1bkavsQsh93w48k/I/0v3637xiXWrZ+ghRwNdKS9V1Tfx3N+LaGh2sqibJpTcjHhe332Ulz8q5tMj1Xz3Uvd9zPvl9W9DYzWIFxNemFY48Db86/uw+WdwcGPPr8uaAvEZ3a+jgo4GulJeevRvBbz0j2JS4mzMz/V8Kf70kckYA9/746eIwCVTTm9r75fWFivMF34PFt7f8/pvfhd2/4913+GaPef6F3xbkwoKGuhKecEYQ95+O4snZfGLr5zZ7VRwSyYP5e/3L6apxUlcTCRZiT4ePqGxxrqN9XI4gJTR1i+Ak8eDZswR5R8a6Ep5Yd+xGr6oaeCeSyaQHGfrcf0RKUP8V0xDtXXbm0AHKN1pjTkSBMO8Kv/QXi5KeWGzq6vigI+p4k5fA71o66mPVdjRQFfKC3n5dmZmJ/u++aQveh3orjPyovet21Q9Qw9XGuhK9aCqvomPSxzd9mwZUL0N9CGpEJ0IR1zjyQR63kvlN9qGrpQbxZUn2FxgNbMUlNViDMFztWdvA13Eamax74W4dIhJ8F9tKqA00JVy48HX97C5oGNc/pz0OKaNGOBJJjxpcFi33gY6wMhZVqCPmOWXklRw0EBXqouTTa38/fNKvnb2aO652LooKCEmioiIIJlFq6EaEKsZxVtX/Rou+o/e/RJQIUcDXaku/v55BY0tTi6dOow0X1+y7wsN1VYwR/TiK7CICIhP919NKihooKuw4HQarvnNBxwoq+v3tlqcTuKiI5nXzdWgAdUW6Ep1oYGuwsKnR6rZXVrNZdOGtU8s0R+zRqUQE+XFOCmBoIGuPNBAV2EhL9+aTPmn10wPzmYSX9JAVx5oP/Qg4TjRxG+2HOSFbYfdTjysure5wM6sUSnhH+agga480jP0IPHCh4d5bOMBACYOTQze9tsgZK9t4JPSar5zyYRAl+J/R3eBfR+M0Pk+1en0DD1IvJNvZ1xmPFER0j7FmfLOlnyrv7i7KeHCitMJz11h3U/Rqz3V6bw6QxeRpcATQCTwO2PMw12e/y5wY6dtTgYyjTFVPqw1bFXWNbK71MFdSyaw7VAlm/PtfPfSiUT2ot+z02lo7aGpxhZ5+u9vYwwtztBu4nknv4zhybFMHt6LftmhqO4LaKqzxkG/4LuBrkYFoR4DXUQigaeAi4FSYLuIvG6M2de2jjHm58DPXetfBdytYe69LQXl7ZeWx0VH8tM39zPzx38j798vJCup58GgKusaWfL4uzhONHe73pqrpnDLubmnLLt+3TY+Kgz9Q3XDPM9TwoWNtrk+R86GiCDtgaMCypsz9HnAQWPMIQARWQ8sA/Z5WP8G4GXflDc45BXYyUyMYeqIJHIy4viipoH/fr+QPUerWexFoOfl23GcaOa283NJHuJ+rO4//vMIGz4+ckqgl1Sd4KPCKpZOHca0kUk+25+BJiJcM2tkoMvwv/bJm3W0ROWeN4E+Eijp9LgUmO9uRRGJA5YCqz08fztwO8Do0TomM0Bzq5OtB8q5bNowIiKExFgbdyw6g/9+v5DCihNebWNzgZ2hSTE8cPlkj2epxsBjGw9QXttIZmJM++sA7l06kbGZOmBT0HMctm61/Vx54E2gu0sIT42uVwEfeGpuMcasA9YBzJkzJ7Qbbn3gWPVJntj0GbUNLad8oZcaZyMpNorCilOvemxobuU3Wz7nRGPLKcu3HqjgyhnDu21yWDQpi8c2HmBLgZ3r5oziTx8f4fkPD5OTHqdhHiqOH4b4LLD5cTYkFdK8CfRSoPMpQTZw1MO6K9DmFq/9745S1m8vITcjnvPHd8ywLiLkZiZQWFF/yvob95Xxq3c+Y4gtks7fl9qiIvhSD00OU0ckMTQphs0Fdi6fPpx7X/0EBO65eBB09QsXjmKdbUh1y5tA3w6MF5Fc4AhWaH+160oikgxcCHzNpxWGscKKekYkx7L5OwtPe25sRvxpX1bm5dtJjbOx4wcX96oHDFi/JBZNzOIvnxxjS0E5Ta1OXrptPgvGZfT84nBRZ4fKg4Guou8qP4fRbls7lQK8CHRjTIuIrAbexuq2+IwxZq+IrHI9v9a16jXA34wx9R42pVwcJ5qItUVyqKKe3Mx4t+vkpMez4eMjHKs+SXRkBE4DWwrsLJyY1eswb7NoUhbrt5fw6N8KSIyJYm7OILt46aWvwNGPA11F/6Tr+ZLyzKt+6MaYN4E3uyxb2+Xxc8BzviosXL34j8N8f8MeUuJstLQalp05wu1647KsoD/n/+Wdsrw/s+acd0YG0VERFFbUc8X04W77pYctY6D8AEz5EsxZGehq+kYiIHtuoKtQQUwv/R9gHxc7ANr7jOdmuD9Dv2jyUB758gwaWlrbl8XaIrls2rA+v3d8TBTP3TKXz8vrWDw5zK+q7OpEJTTXw+izYezCQFejlF9ooA+wwop6zhqdwoGyOuoaWxjrockl1hbJV+b6vnvagjMyWHDGIGo3b9Pe5U+/VFThaxD9zT2wdpc4eGVHyWnLiyrqmTgskfNcoZqT7j7QlY/pRTlqENAzdD+5ft2HNDRb05i1Xb1ZfaKZyvomctLjuWJ6MvVNLYz2wWQMygvtga4X5ajwpWfoftI2TtZ7n3XMHF9YaXUAys2I57zxGbzwjflEDaYvJgPJUQyxKTqOuApreobuJyNThnCoop68fDtXzrB6shS5LhTy1G6u3Kgtg8ba/m+nvEDbz1XY00D3k4q6RgDe+6yifVlBWS0Rgk/mvBwUHCXwxAwwTt9sb8qXfLMdpYKUBrofNDS3UtPQQlJsFOW1jVSfbCZ5iI2tB8qZPSY1eCcfDjblBVaYL/o+pOb2vH5Pcs7t/zaUCmIa6H5QXmudnc8fm87GfWUUVdQzLDmWvUdruHfpxABXF0IcRdbtrK9BkvsLsJRSHTTQ/cBe2wDA/Nw0Nu4r4393lpB/zGoH7s+VnoOOoxgioyGh7xdTKTWYaKD7gb3GOkOfk5OGCPxhWzFDbJFcMWM4E4eG+TRpvuQohuRREKE9gZTyhv5P8QO7q8klO3UI2anW2NXXzx3FU189K/ynSfMlHS5WqV7RQPcDe20DURFCWlx0+5Wgi7Sppfc00JXqFW1y8QN7TSMZCTFERAiThyexq8TB/Nxuhqptqgdn66nLomKsn2BkjPu+4bY4iOz0T6qxzvsuh5HRYOs0f2rTCagv10BXqhc00P3AXttIVpIVxt9eMp6bzh5DrM1DV8X9f4b/cTPGddQQ+PY/g7N3R95P4L3HTl+eNg7u3AkisHs9bPim99uMsMG3tlm/ENZeAFf9wlqemuOTkpUaDDTQ/cBe28jIFOtsMyEmioSYbj7mIzshIgou+nHHsupS+MfTYN8XnIFeut0K2rm3dSwr/hDy34AGBwxJtfbLFg+LHuh5eycq4P1fwBefQEQkNFbDnj9az+kZulJe00D3g/LaBs4cleLdyo5iSM6GBas7llUfsQL9+GG/1NdvjmIYOfvUmlNGW4F+/LAV6McPQ9rYU9fxpKHGCnTHYRDXXzKHP+jYrlLKK/qlqI+1tDqprG8iK9HL9m9H8elDuiYOs5og2kYIDCbOVusviK41twVvW829+UIzNsn6JeAo7nj9yeMQGWPNcq+U8ooGuo9V1DVhDO1t6D06fvj04IuItIZ5DcZArzkKzpbTa051Bbyj2PrS1FHcscwbKWNODXSwPgPtg66U17TJxcfarhLNSoztYU2g+STU291PupAyOjgDvX1c8S6BHpsCMUnW8yeqrOneetNckjIayvM7mlxAJ6NQqpf09MfH2q4S9arJxeGa0cjdmWywB3rX3iciHTX3Zbq3U14rvX+9UkoD3dfarhL1qsnF09lu27J6u3UWH0zaak7OPv259lDuZr88SRkDLQ3QfAKGz+j965VS2uTia2U1DYhARkI3gb7vddiwClqt8Hcf6DnW7cNjrLPfYNHaBInD3V/0lDIGCt6E177hetyLQO78V0ruBXBsd+/a4JVSGui+Zq9tIC0uGlt3U8sVvW9dQXnOHZCU7b6v+YRL4cL7oSXIztABRs13v3zebdbVnsZpdVnszXRvuRda454bY30uKWNg4uW+qVepQUID3cd2FB1n0vAeRlR0FFuBd/F/eF4nNgkWfc+3xflb+ji4aE3fXmuLhQvv7Xg87zbP6yql3NI2dB8qqTrBZ/Y6Fk3soe90b7v0KaWUFzTQfWhzgR3oYRKLtj7a+oWfUsrHNNB9aNuhSrJThzA2M8HzSiePQ1OtBrpSyue8CnQRWSoiBSJyUETu97DOQhHZJSJ7ReRd35YZGg6V1/c8I1Ff+mgrpZQXegx0EYkEngIuA6YAN4jIlC7rpAC/Aa42xkwFrvN9qcHN6TQUVdaTmxHf/YrtfbS1DV0p5VvenKHPAw4aYw4ZY5qA9cCyLut8FfijMaYYwBhj922Zwe+LmgYamp3kZnob6HqGrpTyLW8CfSRQ0ulxqWtZZxOAVBHZIiI7ReTr7jYkIreLyA4R2VFeXt63ioNUYUU9ALnpXgR6TDIMSfF/UUqpQcWbQHd3maLp8jgKmA1cAVwK/FBEJpz2ImPWGWPmGGPmZGZm9rrYYNYe6D2dobsbXVEppXzAmwuLSoFRnR5nA0fdrFNhjKkH6kVkKzATOOCTKkNAYUU9sbYIhvY0ymLbRUVKKeVj3pyhbwfGi0iuiEQDK4DXu6zzf8D5IhIlInHAfGC/b0sNboUV9eSkxxMR0c24K30ZJ1wppbzU4xm6MaZFRFYDbwORwDPGmL0issr1/FpjzH4ReQv4BHACvzPG7PFn4cGmqKK+50v++zJOuFJKecmrsVyMMW8Cb3ZZtrbL458DP/ddaaGjpdVJcdUJlk4b1v2K2gddKeVHeqWoD5QeP0mL03jRB10DXSnlPxroPtDWw2VOzUb47RLY9GP3K2ofdKWUH2mg+8AhV6CPPPwnOLIDtv/O+gK0K0exNfdmb8YJV0opL2mg+0BRRT1JsVHYakutBY010OA4fUUdZVEp5Uca6D7wSamDCVnxSHVJRx9zdxM860VFSik/0kDvp/LaRnaXVnNZToQ132bOedYTXQO9fRx07YOulPIPDfR+2uKa1GLhMNfcnznnW7ddA72+wpofVC8qUkr5iQZ6P20usJOVGMPYqEprwfCZEJ14eqBrDxellJ9poPdDc6uT9w5UsGhiFtI5sFNGuwl07YOulPIvr64UVe5tL6rivOYPuKdqDxz5HOKzwDbECu3DH8DLX4WRsyDnAnjvcetFyaO636hSSvWRBno/bM63c2NUHlnln0PaOJh6rfXEtC9DdanVJ/2zv8HMIqgogOlfgdikgNaslApfGuj98E6+netiW5GRc+HmTgNQzrjO+tnxDLxxN5R8ZLWtf/m3gStWKRX2tA29jw5X1nOovJ706Fawxblfqa29vOKAtp0rpfxOA72P8vKt7opJkc0Q7SnQO3VR1EBXSvmZBnofvfdZBbkZ8dicJz2foSdnd9zXQFdK+ZkGeh99Zq9l+shkaDrhOdBtQyBhqHVfA10p5Wca6H3Q2NJK6fGT5GTEQ/MJz00u0BHkesm/UsrPNND7oLjyBMbAuLRocDaDrZuJLdoCXfufK6X8TLst9kHbhBZjk10TQnd3hj7xcmtgLlvsAFSmlBrMNND7oC3QxyS5At02xPPK05dbP0op5Wfa5NIHRZX1pMdHW10WofsmF6WUGiAa6H1wqLzemhC6yTpT77bJRSmlBogGeh8UVdZ39HABz90WlVJqAGmg91J9YwtlNY3WGboGulIqiOiXor3w591HOVRuNbNYTS6uQNcmF6VUENBA74U7X/64/X5uRjyUt52h65eiSqnA0yaXPspJ79zk0k23RaWUGiBeBbqILBWRAhE5KCL3u3l+oYhUi8gu18+PfF9q8BieHMuQ6EhtclFKBZUem1xEJBJ4CrgYKAW2i8jrxph9XVZ9zxhzpR9qDBoxURE0tjiZOCzRWtDs6raoTS5KqSDgzRn6POCgMeaQMaYJWA8s829Zwael1Ulji5Mb5o3mkeUzrIVNJyAiCqKiA1ucUkrhXaCPBEo6PS51LevqHBHZLSJ/FZGp7jYkIreLyA4R2VFeXt6HcgOnvqkVgHGZ8WQlusZlae5mLHSllBpg3gS6uFlmujz+JzDGGDMT+DXwJ3cbMsasM8bMMcbMyczM7FWhgXaiqQWA+JhOrVTN9RroSqmg4U2glwKdx37NBo52XsEYU2OMqXPdfxOwiUiGz6oMAvWNbgK9qYex0JVSagB50w99OzBeRHKBI8AK4KudVxCRYUCZMcaIyDysXxSVvi7W7wq3QnnBqcvGXwwnKond8wFfizxEZkMqMMJ6rrmb2YqUUmqA9RjoxpgWEVkNvA1EAs8YY/aKyCrX82uB5cC/ikgLcBJYYYzp2iwT3IyBl2+AprpTl09bDsd2kV15kIds4Nh1EOa/YT3XUA0xSQNfq1JKueHVlaKuZpQ3uyxb2+n+k8CTvi1tgNWXW2F+0Ro482vWsldXQuVBOH6Y4vFfZ3/+PhbWd/p+2FECY84JSLlKKdWVXinaxlFs3WZNgYRM6ydtLJTtAWczVXG5HDLDia47Ak4ntLZAzRGd/FkpFTR0LJc2x4us284BnTIanNaXoVW2YZSaTMTZDLXHrLlETasGulIqaGigt2k7Q+88mXNqTvvd8sihlJjMjnWdrtmKNNCVUkFCA72Noxji0iEmoWNZp7Auk0xK3Qb6mAEsUimlPNNAb+M4fPrZdtvjhKHUtERx3DbUta4r0CUCktxdNKuUUgNPAx3g2G4oPwDZc05dHp8FkTGQMob6plaiYuIgZig4iqwvRRNH6DguSqmgoYFuDDxzmXUZf9ZNpz4XEQHDpsOw6dTXthAfHWk1sTiKrUDX9nOlVBDRQG8+YYX5jBVw/ndOf/7r/weRNk68+Il12X/KaDiywwr0nPMGvl6llPJA+6GfdFi3o8+GSDe/32ISICqGusYW4qNdgV5dCrVHIVW/EFVKBQ8N9IZq6zY2udvV6hpbiIuJ7Oibbpza5KKUCioa6F4Eel1jCwVf1DJhaOKpZ+Ua6EqpIKJt6O2BnuJxlfc/q6C51bBoYhakdOrVooGulAoieobeFuhDUtoX7TlSjb2mof1xXn4ZibFRzMlJheRsa6H2QVdKBRkN9C5NLo0traxYt40f/7ljDuyPCqs4Z2w6tsgIiIqBxOGQlA2RtkBUrJRSbmmgtwW6a1zzjwqrqGtsYeuBcppanDS1OCmuOsHEYYkdr8maDJkTA1CsUkp5pm3oDQ5r1iHXFZ/v7LcDUNvYwo6iKoYmx+I0kJsR3/Gaa3+L+6lWlVIqcDTQG6pP6eGy9UA583LT2FXs4NbndzAzOwWAnM6BHh9W06UqpcKENrl0CvSG5lYOVdRz7rgMfnbtdIYnx/LhIWtq1LGdA10ppYKQBnqnQC+qrAcgNzOe5bOzueXcXABS4mykxOkgXEqp4KaB3jnQK6xAbzsbXzwpC+jSfq6UUkFKA72huv2iokOuQG9rLx+ZMoRzxqYzPzc9UNUppZTXBveXoicdcLwQzrgIsM7QMxNjSIjp+Fhevv3sABWnlFK9M3jP0Fub4YmZ1n1Xr5XCinpy07V5RSkVmgZvoNccsfqgz70V5n8TgMKKE9perpQKWYM30B3F1u3kq2FIKjUNzVTUNZ7a31wppULI4A3044etW9eIiW09XPQMXSkVqgZvoDuKrRETXaMnFrZ1WczUQFdKhabBHehJI9tHTCysqEcERqfFBbgwpZTqG68CXUSWikiBiBwUkfu7WW+uiLSKyHLflegnjuJTJqgoqqhnRPIQYm2RASxKKaX6rsdAF5FI4CngMmAKcIOITPGw3n8Cb/u6SL/oEuiFFfXafq6UCmnenKHPAw4aYw4ZY5qA9cAyN+vdCbwG2H1Yn3+0NFndFl2BbozhkAa6UirEeRPoI4GSTo9LXcvaichI4BpgbXcbEpHbRWSHiOwoLy/vba2+U1MKmPZAr6pvorahRQNdKRXSvAl0dzM5mC6PfwncZ4xp7W5Dxph1xpg5xpg5mZmZXpboB2190FPGAB09XDTQlVKhzJuxXEqBUZ0eZwNHu6wzB1gvIgAZwOUi0mKM+ZMvivS59kC3ztA10JVS4cCbQN8OjBeRXOAIsAL4aucVjDG5bfdF5DngjaANc3D1QY+0ui1iBXpUhJCdOiTAhSmlVN/1GOjGmBYRWY3VeyUSeMYYs1dEVrme77bdPCgdP+zqg27tfmFFPaPT4oiKHLzd8pVSoc+r4XONMW8Cb3ZZ5jbIjTG39L8sP9Mui0qpMDQ4T0kdxZBqfSHqdBqKKut1UC6lVMgLvQku9r0OG1b1bxvN9e1n6GW1DTQ0O/UMXSkV8kIv0NNyYc7K/m0jIgrOvBGAwnLt4aKUCg+hF+jDpls/PnJIuywqpcLE4GxD76Soop6YqAiGJcUGuhSllOqXQR/obT1cIiLcXRCrlFKhI/SaXPqprKYBx4nm9scHy+uYMjwpgBUppZRvDKpAr6xr5PxHNtPU4jxl+bKZIwJUkVJK+c6gCvQtBeU0tTh58KopDHW1mUcInHtGRoArU0qp/htUgZ5XYCczMYabz8nRNnOlVNgZNF+KNrc62XqgnEUTMzXMlVJhadAE+o6i49Q2tLB4UlagS1FKKb8YNIG+ucCOLVI4b3wAJ9ZQSik/GjSBnpdvZ35uOgkxg+prA6XUIDIoAr2k6gQH7XUs0uYWpVQYGxSBnpdvB9D2c6VUWBs0gZ6bEa8DcCmlwlrYB/qJphY+PFTJool6dq6UCm9hH+gfHKykqcXJkska6Eqp8Bb2gZ6XbychJoq5OWmBLkUppfwqrAN9e1EVefllnHdGBtFRYb2rSikVvmO57DlSzXVrPwTg0mlDA1yNUkr5X9gG+qb9ZYjAa/+6gDOzUwJdjlJK+V3YBvrmfDtnjkrhrNGpgS5FKaUGRMgF+rsHynnojX09rveZvY5/v3jCAFSklFLBIeQCPSEmivFDE3pcb+qIJK6bM2oAKlJKqeAQcoE+e0wqs8fMDnQZSikVdLzqyyciS0WkQEQOisj9bp5fJiKfiMguEdkhIuf5vlSllFLd6fEMXUQigaeAi4FSYLuIvG6M6dyQ/Q7wujHGiMgM4BVgkj8KVkop5Z43Z+jzgIPGmEPGmCZgPbCs8wrGmDpjjHE9jAcMSimlBpQ3gT4SKOn0uNS17BQico2I5AN/Af7F3YZE5HZXk8yO8vLyvtSrlFLKA28C3d2MyqedgRtjNhhjJgFfAn7ibkPGmHXGmDnGmDmZmToVnFJK+ZI3gV4KdO7/lw0c9bSyMWYrME5EMvpZm1JKqV7wJtC3A+NFJFdEooEVwOudVxCRM0REXPfPAqKBSl8Xq5RSyrMee7kYY1pEZDXwNhAJPGOM2Ssiq1zPrwW+DHxdRJqBk8D1nb4kVUopNQAkULkrIuXA4T6+PAOo8GE5gaT7Epx0X4KT7guMMca4/RIyYIHeHyKywxgzJ9B1+ILuS3DSfQlOui/d01kflFIqTGigK6VUmAjVQF8X6AJ8SPclOOm+BCfdl26EZBu6Ukqp04XqGbpSSqkuNNCVUipMhFyg9zQ2e7ATkSIR+bRt7HjXsjQR2Sgin7lug3IiVBF5RkTsIrKn0zKPtYvI91zHqUBELg1M1e552Jc1InLEdWx2icjlnZ4Lyn0RkVEisllE9ovIXhH5N9fykDsu3exLKB6XWBH5SER2u/blx67l/j0uxpiQ+cG6UvVzYCzW8AK7gSmBrquX+1AEZHRZ9ghwv+v+/cB/BrpOD7VfAJwF7OmpdmCK6/jEALmu4xYZ6H3oYV/WAN9xs27Q7gswHDjLdT8ROOCqN+SOSzf7EorHRYAE130b8A/gbH8fl1A7Q+9xbPYQtQz4vev+77FGrAw6xhp4rarLYk+1LwPWG2MajTGFwEGs4xcUPOyLJ0G7L8aYY8aYf7ru1wL7sYa3Drnj0s2+eBLM+2KMMXWuhzbXj8HPxyXUAt2rsdmDnAH+JiI7ReR217KhxphjYP2jBrICVl3veao9VI/Vatd0is90+nM4JPZFRHKAWVhngyF9XLrsC4TgcRGRSBHZBdiBjcYYvx+XUAt0r8ZmD3LnGmPOAi4D7hCRCwJdkJ+E4rF6GhgHnAkcAx5zLQ/6fRGRBOA14C5jTE13q7pZFuz7EpLHxRjTaow5E2vI8XkiMq2b1X2yL6EW6L0amz0YGWOOum7twAasP6vKRGQ4gOvWHrgKe81T7SF3rIwxZa7/hE7gt3T8yRvU+yIiNqwAfNEY80fX4pA8Lu72JVSPSxtjjAPYAizFz8cl1AK9x7HZg5mIxItIYtt94BJgD9Y+3Oxa7Wbg/wJTYZ94qv11YIWIxIhILjAe+CgA9Xmt7T+ayzVYxwaCeF9ERID/BvYbYx7v9FTIHRdP+xKixyVTRFJc94cAFwH5+Pu4BPrb4D58e3w51rffnwPfD3Q9vax9LNY32buBvW31A+nAO8Bnrtu0QNfqof6Xsf7kbcY6o/hGd7UD33cdpwLgskDX78W+vAB8Cnzi+g82PNj3BTgP60/zT4Bdrp/LQ/G4dLMvoXhcZgAfu2reA/zItdyvx0Uv/VdKqTARak0uSimlPNBAV0qpMKGBrpRSYUIDXSmlwoQGulJKhQkNdKWUChMa6EopFSb+P4UpLeCiwDo3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "flower_loss[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a833896d-809e-4461-a29b-f27dcd59ec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43269991874694824, 0.8222222328186035]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93775cb-836c-4a9c-a78c-174a497de24c",
   "metadata": {},
   "source": [
    "0.97% accuracy is enough for us so let's start developing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e582361c-6648-4e05-9709-482e0216b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "659d757d-0346-4dfb-a40a-8fcbae50b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69621863-bcc7-4a33-b916-0e176d747f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 1.0975 - accuracy: 0.2867\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.0966 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0958 - accuracy: 0.3600\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0948 - accuracy: 0.3733\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0939 - accuracy: 0.3800\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0927 - accuracy: 0.3933\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0916 - accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0902 - accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0887 - accuracy: 0.3800\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0870 - accuracy: 0.3867\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0846 - accuracy: 0.4333\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0818 - accuracy: 0.4733\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0789 - accuracy: 0.4867\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0759 - accuracy: 0.5067\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0726 - accuracy: 0.5400\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0698 - accuracy: 0.5400\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0666 - accuracy: 0.5400\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0632 - accuracy: 0.5400\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0590 - accuracy: 0.5933\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0543 - accuracy: 0.6667\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.7133\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0436 - accuracy: 0.7533\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0382 - accuracy: 0.8067\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.8133\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0263 - accuracy: 0.8333\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0201 - accuracy: 0.8400\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0135 - accuracy: 0.8667\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0069 - accuracy: 0.8667\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0001 - accuracy: 0.8600\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9932 - accuracy: 0.8533\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9864 - accuracy: 0.8533\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9794 - accuracy: 0.8533\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9727 - accuracy: 0.8600\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9654 - accuracy: 0.8600\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9585 - accuracy: 0.8467\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9513 - accuracy: 0.8467\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9444 - accuracy: 0.8400\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9373 - accuracy: 0.8333\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9302 - accuracy: 0.8333\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9230 - accuracy: 0.8267\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9159 - accuracy: 0.8267\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9089 - accuracy: 0.8267\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9018 - accuracy: 0.8133\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8946 - accuracy: 0.8133\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8874 - accuracy: 0.8133\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8805 - accuracy: 0.8067\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8733 - accuracy: 0.8067\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8664 - accuracy: 0.7867\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8592 - accuracy: 0.7933\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.7933\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.8452 - accuracy: 0.7867\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8384 - accuracy: 0.7800\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.7800\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8247 - accuracy: 0.7800\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.7733\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8108 - accuracy: 0.7733\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8042 - accuracy: 0.7867\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.7867\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7908 - accuracy: 0.7733\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7842 - accuracy: 0.7733\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7776 - accuracy: 0.7733\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.7667\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.7667\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7577 - accuracy: 0.7667\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7512 - accuracy: 0.7667\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.7667\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.7867\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.7867\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.8400\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7159 - accuracy: 0.8533\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.8600\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.8667\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.8733\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.8733\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6835 - accuracy: 0.8733\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.8800\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.8667\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.8600\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.8600\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6539 - accuracy: 0.8600\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.8667\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.8667\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.8667\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.8667\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6270 - accuracy: 0.8667\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.8667\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.8800\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.8933\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.8933\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6023 - accuracy: 0.8933\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.8867\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5930 - accuracy: 0.9000\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5885 - accuracy: 0.9000\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5841 - accuracy: 0.9000\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.9067\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.9067\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.9000\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.9067\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.9067\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.9067\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5549 - accuracy: 0.9067\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.9067\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.9067\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.9067\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.9067\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.9067\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5323 - accuracy: 0.9067\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5286 - accuracy: 0.9067\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.9067\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5217 - accuracy: 0.9067\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.9067\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5151 - accuracy: 0.9133\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.9267\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5083 - accuracy: 0.9267\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5051 - accuracy: 0.9267\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.9267\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.9200\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4957 - accuracy: 0.9267\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.9267\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.9267\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.9267\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.9267\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.9200\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.9200\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.9267\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.9333\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.9200\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.9267\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.9267\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.9267\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.9267\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.9333\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.9333\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.9333\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.9333\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.9400\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.9400\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.9400\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.9400\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.9400\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.9400\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.9333\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.9333\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.9333\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.9333\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.9333\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.9400\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.9400\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.9400\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.9400\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.9400\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.9533\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.9533\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.9467\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.9467\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4026 - accuracy: 0.9400\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.9400\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.9533\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.9533\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.9533\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3929 - accuracy: 0.9533\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.9533\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.9533\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3874 - accuracy: 0.9467\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.9533\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3836 - accuracy: 0.9533\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.9533\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3800 - accuracy: 0.9533\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.9533\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3764 - accuracy: 0.9533\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3748 - accuracy: 0.9533\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.9533\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.9533\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3694 - accuracy: 0.9533\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.9600\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.9600\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.9600\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.9533\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.9533\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.9533\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.9533\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3562 - accuracy: 0.9600\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.9600\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.9533\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.9533\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.9533\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.9533\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.9533\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.9533\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.9533\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.9533\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.9533\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.9533\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.9533\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.9533\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.9533\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.9533\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.9533\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.9533\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.9533\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.9600\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.9600\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.9600\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.9600\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3220 - accuracy: 0.9600\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3207 - accuracy: 0.9533\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.9533\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.9533\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9533\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3153 - accuracy: 0.9533\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3141 - accuracy: 0.9600\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.9600\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3113 - accuracy: 0.9600\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3101 - accuracy: 0.9600\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3089 - accuracy: 0.9600\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3075 - accuracy: 0.9600\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3063 - accuracy: 0.9600\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3049 - accuracy: 0.9600\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3036 - accuracy: 0.9667\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3023 - accuracy: 0.9600\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3010 - accuracy: 0.9600\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2998 - accuracy: 0.9600\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2985 - accuracy: 0.9600\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.9600\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.9600\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2949 - accuracy: 0.9600\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2937 - accuracy: 0.9600\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2924 - accuracy: 0.9600\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2912 - accuracy: 0.9600\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.9600\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2889 - accuracy: 0.9600\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2877 - accuracy: 0.9600\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2865 - accuracy: 0.9600\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2853 - accuracy: 0.9600\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2842 - accuracy: 0.9600\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.9600\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2820 - accuracy: 0.9600\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2808 - accuracy: 0.9600\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.9600\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.9600\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2774 - accuracy: 0.9600\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.9600\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.9600\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2743 - accuracy: 0.9600\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2731 - accuracy: 0.9600\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2719 - accuracy: 0.9600\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2710 - accuracy: 0.9600\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2698 - accuracy: 0.9600\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9533\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2677 - accuracy: 0.9533\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2666 - accuracy: 0.9533\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9533\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2646 - accuracy: 0.9600\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2635 - accuracy: 0.9600\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2625 - accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2604 - accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.9600\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2574 - accuracy: 0.9600\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.9600\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2554 - accuracy: 0.9600\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2544 - accuracy: 0.9600\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2534 - accuracy: 0.9600\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2525 - accuracy: 0.9600\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2515 - accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2506 - accuracy: 0.9600\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2495 - accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2487 - accuracy: 0.9600\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2477 - accuracy: 0.9733\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.9733\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2438 - accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2431 - accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9600\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2412 - accuracy: 0.9600\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.9600\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9600\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.9600\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2377 - accuracy: 0.9600\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9600\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9600\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2332 - accuracy: 0.9600\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9600\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2314 - accuracy: 0.9600\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2306 - accuracy: 0.9600\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2297 - accuracy: 0.9600\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2289 - accuracy: 0.9600\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9600\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2272 - accuracy: 0.9600\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2264 - accuracy: 0.9600\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2256 - accuracy: 0.9600\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9600\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2239 - accuracy: 0.9600\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2231 - accuracy: 0.9600\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.2224 - accuracy: 0.9600\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18ff85f50a0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "635cf21a-9eb6-4a4f-9ea7-f817c6ef8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flower_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78a12116-ca16-4027-bbef-268479710e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f57f67-9c79-4d09-9b3f-653abfa39100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flower_scaler.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'flower_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7196a744-472f-4c14-a49a-e0a301088c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "100           6.3          3.3           6.0          2.5  virginica\n",
       "101           5.8          2.7           5.1          1.9  virginica\n",
       "102           7.1          3.0           5.9          2.1  virginica\n",
       "103           6.3          2.9           5.6          1.8  virginica\n",
       "104           6.5          3.0           5.8          2.2  virginica"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower[flower['species'] == 'virginica'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79b09c6b-ef68-4a55-8078-c92679d92e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46101dd3-a4eb-4575-bd6a-afbe7318a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('flower_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181c1911-bae5-4670-b903-d6c140954723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e7171a-4dbf-4d0e-821f-7eafa88fc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('flower_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099d2ca3-805e-4c02-b62a-a4708048f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\"sepal_length\":6.3,\n",
    "                 \"sepal_width\":3.3,\n",
    "                 \"petal_length\":6.0,\n",
    "                 \"petal_width\":2.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "322fa81b-118e-4d14-a996-9f834dc1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fun(model,scaler,data):\n",
    "    s_len = data[\"sepal_length\"]\n",
    "    s_wid = data[\"sepal_width\"]\n",
    "    p_len = data[\"petal_length\"]\n",
    "    p_wid = data[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    classes = np.array(['setosa','versicolor','verginica'])\n",
    "    \n",
    "    #flower = scaler.fit_transform(flower)\n",
    "    flower_scaled = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower_scaled)\n",
    "    #class_indx = np.argmax(model.predict(flower_scaled),axis=-1)\n",
    "    \n",
    "    return class_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aec796d-b72f-4bac-8dfa-946121564957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gaurav\\anaconda3\\envs\\deeplnenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_fun(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d43ad48-ab94-4ad3-912e-c39284452ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c991ef-6c19-440f-96f0-6c6e8d096163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
